{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6063 - loss: 0.7190 - val_accuracy: 0.0000e+00 - val_loss: 0.9706\n",
      "Epoch 2/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.5776 - loss: 0.6921 - val_accuracy: 0.0000e+00 - val_loss: 0.9361\n",
      "Epoch 3/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.5925 - loss: 0.6769 - val_accuracy: 0.0000e+00 - val_loss: 0.9558\n",
      "Epoch 4/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.6084 - loss: 0.6707 - val_accuracy: 0.0000e+00 - val_loss: 0.9487\n",
      "Epoch 5/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.6062 - loss: 0.6699 - val_accuracy: 0.0000e+00 - val_loss: 0.9469\n",
      "Epoch 6/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.6148 - loss: 0.6632 - val_accuracy: 0.0000e+00 - val_loss: 0.9489\n",
      "Epoch 7/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.6099 - loss: 0.6588 - val_accuracy: 0.0000e+00 - val_loss: 0.9479\n",
      "Epoch 8/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.6272 - loss: 0.6432 - val_accuracy: 0.0000e+00 - val_loss: 0.9099\n",
      "Epoch 9/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.6351 - loss: 0.6318 - val_accuracy: 0.0137 - val_loss: 0.9082\n",
      "Epoch 10/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - accuracy: 0.6440 - loss: 0.6254 - val_accuracy: 0.4311 - val_loss: 0.8763\n",
      "Epoch 11/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.6517 - loss: 0.6240 - val_accuracy: 0.4898 - val_loss: 0.8724\n",
      "Epoch 12/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.6427 - loss: 0.6308 - val_accuracy: 0.4775 - val_loss: 0.9037\n",
      "Epoch 13/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.6630 - loss: 0.6159 - val_accuracy: 0.5419 - val_loss: 0.8584\n",
      "Epoch 14/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 956us/step - accuracy: 0.6614 - loss: 0.6153 - val_accuracy: 0.5317 - val_loss: 0.8709\n",
      "Epoch 15/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.6689 - loss: 0.6130 - val_accuracy: 0.5454 - val_loss: 0.8605\n",
      "Epoch 16/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.6667 - loss: 0.6074 - val_accuracy: 0.5568 - val_loss: 0.8583\n",
      "Epoch 17/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.6705 - loss: 0.6059 - val_accuracy: 0.5362 - val_loss: 0.8863\n",
      "Epoch 18/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6743 - loss: 0.6069 - val_accuracy: 0.5489 - val_loss: 0.8695\n",
      "Epoch 19/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - accuracy: 0.6741 - loss: 0.6092 - val_accuracy: 0.5381 - val_loss: 0.8765\n",
      "Epoch 20/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.6705 - loss: 0.6159 - val_accuracy: 0.5327 - val_loss: 0.8792\n",
      "Epoch 21/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 966us/step - accuracy: 0.6693 - loss: 0.6097 - val_accuracy: 0.5352 - val_loss: 0.8779\n",
      "Epoch 22/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.6787 - loss: 0.6079 - val_accuracy: 0.5381 - val_loss: 0.8754\n",
      "Epoch 23/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.6841 - loss: 0.6006 - val_accuracy: 0.5403 - val_loss: 0.8653\n",
      "Epoch 24/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.6850 - loss: 0.6062 - val_accuracy: 0.5543 - val_loss: 0.8491\n",
      "Epoch 25/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.6755 - loss: 0.6087 - val_accuracy: 0.5454 - val_loss: 0.8608\n",
      "Epoch 26/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.6842 - loss: 0.6075 - val_accuracy: 0.5390 - val_loss: 0.8734\n",
      "Epoch 27/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.6803 - loss: 0.6091 - val_accuracy: 0.5270 - val_loss: 0.8827\n",
      "Epoch 28/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.6803 - loss: 0.6040 - val_accuracy: 0.5276 - val_loss: 0.8803\n",
      "Epoch 29/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.6848 - loss: 0.5967 - val_accuracy: 0.5333 - val_loss: 0.8727\n",
      "Epoch 30/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 933us/step - accuracy: 0.6900 - loss: 0.6026 - val_accuracy: 0.5241 - val_loss: 0.8788\n",
      "Epoch 31/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6789 - loss: 0.6051 - val_accuracy: 0.5378 - val_loss: 0.8617\n",
      "Epoch 32/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.6785 - loss: 0.6045 - val_accuracy: 0.5260 - val_loss: 0.8746\n",
      "Epoch 33/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.6745 - loss: 0.6095 - val_accuracy: 0.5337 - val_loss: 0.8746\n",
      "Epoch 34/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.6846 - loss: 0.5990 - val_accuracy: 0.5390 - val_loss: 0.8588\n",
      "Epoch 35/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.6834 - loss: 0.6038 - val_accuracy: 0.5263 - val_loss: 0.8722\n",
      "Epoch 36/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.6837 - loss: 0.6018 - val_accuracy: 0.5276 - val_loss: 0.8666\n",
      "Epoch 37/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 896us/step - accuracy: 0.6818 - loss: 0.6026 - val_accuracy: 0.5197 - val_loss: 0.8768\n",
      "Epoch 38/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.6833 - loss: 0.6013 - val_accuracy: 0.5219 - val_loss: 0.8716\n",
      "Epoch 39/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6820 - loss: 0.6018 - val_accuracy: 0.5175 - val_loss: 0.8754\n",
      "Epoch 40/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.6802 - loss: 0.6043 - val_accuracy: 0.5276 - val_loss: 0.8570\n",
      "Epoch 41/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.6870 - loss: 0.6060 - val_accuracy: 0.5302 - val_loss: 0.8604\n",
      "Epoch 42/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - accuracy: 0.6911 - loss: 0.5934 - val_accuracy: 0.5171 - val_loss: 0.8798\n",
      "Epoch 43/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6834 - loss: 0.6015 - val_accuracy: 0.5165 - val_loss: 0.8659\n",
      "Epoch 44/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.6806 - loss: 0.6014 - val_accuracy: 0.5289 - val_loss: 0.8543\n",
      "Epoch 45/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6852 - loss: 0.6025 - val_accuracy: 0.5095 - val_loss: 0.8920\n",
      "Epoch 46/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.6989 - loss: 0.5894 - val_accuracy: 0.5244 - val_loss: 0.8557\n",
      "Epoch 47/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.6951 - loss: 0.5930 - val_accuracy: 0.5254 - val_loss: 0.8482\n",
      "Epoch 48/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6912 - loss: 0.5937 - val_accuracy: 0.5276 - val_loss: 0.8479\n",
      "Epoch 49/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6910 - loss: 0.5940 - val_accuracy: 0.5143 - val_loss: 0.8586\n",
      "Epoch 50/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.6908 - loss: 0.5944 - val_accuracy: 0.5181 - val_loss: 0.8589\n",
      "Epoch 51/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6863 - loss: 0.5950 - val_accuracy: 0.5102 - val_loss: 0.8678\n",
      "Epoch 52/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - accuracy: 0.6883 - loss: 0.5992 - val_accuracy: 0.5086 - val_loss: 0.8620\n",
      "Epoch 53/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.6920 - loss: 0.5958 - val_accuracy: 0.5124 - val_loss: 0.8539\n",
      "Epoch 54/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6866 - loss: 0.5953 - val_accuracy: 0.5130 - val_loss: 0.8633\n",
      "Epoch 55/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.6866 - loss: 0.6003 - val_accuracy: 0.4889 - val_loss: 0.8897\n",
      "Epoch 56/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.6897 - loss: 0.5938 - val_accuracy: 0.4990 - val_loss: 0.8838\n",
      "Epoch 57/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.6924 - loss: 0.6003 - val_accuracy: 0.5086 - val_loss: 0.8569\n",
      "Epoch 58/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.6868 - loss: 0.5984 - val_accuracy: 0.4886 - val_loss: 0.8772\n",
      "Epoch 59/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.6938 - loss: 0.5962 - val_accuracy: 0.4924 - val_loss: 0.8707\n",
      "Epoch 60/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.6931 - loss: 0.5938 - val_accuracy: 0.4968 - val_loss: 0.8638\n",
      "Epoch 61/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.6871 - loss: 0.5996 - val_accuracy: 0.4994 - val_loss: 0.8586\n",
      "Epoch 62/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.6926 - loss: 0.5936 - val_accuracy: 0.5006 - val_loss: 0.8593\n",
      "Epoch 63/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.6918 - loss: 0.5930 - val_accuracy: 0.5025 - val_loss: 0.8581\n",
      "Epoch 64/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.6920 - loss: 0.5952 - val_accuracy: 0.5016 - val_loss: 0.8521\n",
      "Epoch 65/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.6862 - loss: 0.5947 - val_accuracy: 0.5013 - val_loss: 0.8618\n",
      "Epoch 66/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.6919 - loss: 0.5923 - val_accuracy: 0.4848 - val_loss: 0.8752\n",
      "Epoch 67/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6904 - loss: 0.5955 - val_accuracy: 0.5006 - val_loss: 0.8543\n",
      "Epoch 68/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.6938 - loss: 0.5940 - val_accuracy: 0.4975 - val_loss: 0.8591\n",
      "Epoch 69/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.6910 - loss: 0.5933 - val_accuracy: 0.4825 - val_loss: 0.8675\n",
      "Epoch 70/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.6923 - loss: 0.5933 - val_accuracy: 0.5035 - val_loss: 0.8406\n",
      "Epoch 71/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.6926 - loss: 0.5898 - val_accuracy: 0.4968 - val_loss: 0.8495\n",
      "Epoch 72/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.6905 - loss: 0.5939 - val_accuracy: 0.4930 - val_loss: 0.8475\n",
      "Epoch 73/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.6935 - loss: 0.5921 - val_accuracy: 0.4768 - val_loss: 0.8754\n",
      "Epoch 74/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6984 - loss: 0.5907 - val_accuracy: 0.5032 - val_loss: 0.8444\n",
      "Epoch 75/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.6933 - loss: 0.5905 - val_accuracy: 0.4813 - val_loss: 0.8634\n",
      "Epoch 76/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 921us/step - accuracy: 0.6950 - loss: 0.5931 - val_accuracy: 0.4883 - val_loss: 0.8506\n",
      "Epoch 77/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.6881 - loss: 0.5917 - val_accuracy: 0.4968 - val_loss: 0.8451\n",
      "Epoch 78/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.6874 - loss: 0.5964 - val_accuracy: 0.4800 - val_loss: 0.8602\n",
      "Epoch 79/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.6901 - loss: 0.5986 - val_accuracy: 0.5041 - val_loss: 0.8325\n",
      "Epoch 80/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.6845 - loss: 0.5992 - val_accuracy: 0.4892 - val_loss: 0.8526\n",
      "Epoch 81/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.6800 - loss: 0.5992 - val_accuracy: 0.4886 - val_loss: 0.8574\n",
      "Epoch 82/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.6910 - loss: 0.5925 - val_accuracy: 0.4803 - val_loss: 0.8580\n",
      "Epoch 83/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.6866 - loss: 0.5974 - val_accuracy: 0.4638 - val_loss: 0.8753\n",
      "Epoch 84/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.6833 - loss: 0.5974 - val_accuracy: 0.4797 - val_loss: 0.8494\n",
      "Epoch 85/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.6939 - loss: 0.5908 - val_accuracy: 0.4673 - val_loss: 0.8577\n",
      "Epoch 86/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6940 - loss: 0.5883 - val_accuracy: 0.4790 - val_loss: 0.8421\n",
      "Epoch 87/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.6912 - loss: 0.5914 - val_accuracy: 0.4711 - val_loss: 0.8688\n",
      "Epoch 88/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6938 - loss: 0.5905 - val_accuracy: 0.4679 - val_loss: 0.8639\n",
      "Epoch 89/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.6900 - loss: 0.5935 - val_accuracy: 0.4521 - val_loss: 0.8693\n",
      "Epoch 90/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.6900 - loss: 0.5919 - val_accuracy: 0.4724 - val_loss: 0.8543\n",
      "Epoch 91/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.6821 - loss: 0.5943 - val_accuracy: 0.4610 - val_loss: 0.8544\n",
      "Epoch 92/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.6899 - loss: 0.5898 - val_accuracy: 0.4654 - val_loss: 0.8552\n",
      "Epoch 93/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - accuracy: 0.6814 - loss: 0.5942 - val_accuracy: 0.4771 - val_loss: 0.8385\n",
      "Epoch 94/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.6930 - loss: 0.5887 - val_accuracy: 0.4835 - val_loss: 0.8445\n",
      "Epoch 95/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.6903 - loss: 0.5908 - val_accuracy: 0.4711 - val_loss: 0.8617\n",
      "Epoch 96/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.6890 - loss: 0.5944 - val_accuracy: 0.4673 - val_loss: 0.8588\n",
      "Epoch 97/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.6967 - loss: 0.5859 - val_accuracy: 0.4714 - val_loss: 0.8533\n",
      "Epoch 98/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.6969 - loss: 0.5869 - val_accuracy: 0.4746 - val_loss: 0.8409\n",
      "Epoch 99/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - accuracy: 0.6833 - loss: 0.5992 - val_accuracy: 0.4743 - val_loss: 0.8548\n",
      "Epoch 100/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.6898 - loss: 0.5896 - val_accuracy: 0.4825 - val_loss: 0.8424\n",
      "Epoch 101/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6941 - loss: 0.5819 - val_accuracy: 0.4746 - val_loss: 0.8515\n",
      "Epoch 102/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.6950 - loss: 0.5926 - val_accuracy: 0.4730 - val_loss: 0.8522\n",
      "Epoch 103/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.6887 - loss: 0.5951 - val_accuracy: 0.4803 - val_loss: 0.8399\n",
      "Epoch 104/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 954us/step - accuracy: 0.6942 - loss: 0.5888 - val_accuracy: 0.4733 - val_loss: 0.8414\n",
      "Epoch 105/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.6942 - loss: 0.5876 - val_accuracy: 0.4746 - val_loss: 0.8292\n",
      "Epoch 106/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.6918 - loss: 0.5929 - val_accuracy: 0.4644 - val_loss: 0.8506\n",
      "Epoch 107/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 902us/step - accuracy: 0.6956 - loss: 0.5848 - val_accuracy: 0.4819 - val_loss: 0.8345\n",
      "Epoch 108/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6888 - loss: 0.5908 - val_accuracy: 0.4648 - val_loss: 0.8604\n",
      "Epoch 109/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.6984 - loss: 0.5832 - val_accuracy: 0.4679 - val_loss: 0.8493\n",
      "Epoch 110/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6911 - loss: 0.5876 - val_accuracy: 0.4594 - val_loss: 0.8614\n",
      "Epoch 111/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.6959 - loss: 0.5913 - val_accuracy: 0.4727 - val_loss: 0.8433\n",
      "Epoch 112/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.6978 - loss: 0.5821 - val_accuracy: 0.4629 - val_loss: 0.8529\n",
      "Epoch 113/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 906us/step - accuracy: 0.6880 - loss: 0.5908 - val_accuracy: 0.4705 - val_loss: 0.8506\n",
      "Epoch 114/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.6938 - loss: 0.5848 - val_accuracy: 0.4733 - val_loss: 0.8459\n",
      "Epoch 115/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.6987 - loss: 0.5841 - val_accuracy: 0.4860 - val_loss: 0.8304\n",
      "Epoch 116/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.6927 - loss: 0.5886 - val_accuracy: 0.4657 - val_loss: 0.8498\n",
      "Epoch 117/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6922 - loss: 0.5866 - val_accuracy: 0.4629 - val_loss: 0.8498\n",
      "Epoch 118/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.6949 - loss: 0.5879 - val_accuracy: 0.4686 - val_loss: 0.8454\n",
      "Epoch 119/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.6977 - loss: 0.5812 - val_accuracy: 0.4708 - val_loss: 0.8424\n",
      "Epoch 120/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.6983 - loss: 0.5799 - val_accuracy: 0.4730 - val_loss: 0.8424\n",
      "Epoch 121/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6929 - loss: 0.5868 - val_accuracy: 0.4683 - val_loss: 0.8439\n",
      "Epoch 122/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.6965 - loss: 0.5876 - val_accuracy: 0.4527 - val_loss: 0.8568\n",
      "Epoch 123/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.7011 - loss: 0.5833 - val_accuracy: 0.4594 - val_loss: 0.8456\n",
      "Epoch 124/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6966 - loss: 0.5868 - val_accuracy: 0.4546 - val_loss: 0.8517\n",
      "Epoch 125/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.6914 - loss: 0.5872 - val_accuracy: 0.4667 - val_loss: 0.8444\n",
      "Epoch 126/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.6963 - loss: 0.5870 - val_accuracy: 0.4622 - val_loss: 0.8506\n",
      "Epoch 127/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.6988 - loss: 0.5829 - val_accuracy: 0.4727 - val_loss: 0.8345\n",
      "Epoch 128/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6823 - loss: 0.5972 - val_accuracy: 0.4422 - val_loss: 0.8726\n",
      "Epoch 129/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6937 - loss: 0.5867 - val_accuracy: 0.4514 - val_loss: 0.8694\n",
      "Epoch 130/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.6828 - loss: 0.5941 - val_accuracy: 0.4483 - val_loss: 0.8617\n",
      "Epoch 131/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.6940 - loss: 0.5847 - val_accuracy: 0.4708 - val_loss: 0.8394\n",
      "Epoch 132/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.6972 - loss: 0.5855 - val_accuracy: 0.4711 - val_loss: 0.8436\n",
      "Epoch 133/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - accuracy: 0.6976 - loss: 0.5844 - val_accuracy: 0.4578 - val_loss: 0.8574\n",
      "Epoch 134/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7016 - loss: 0.5823 - val_accuracy: 0.4654 - val_loss: 0.8406\n",
      "Epoch 135/400\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.6895 - loss: 0.5906 - val_accuracy: 0.4584 - val_loss: 0.8530\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.7223 - loss: 0.5602\n",
      "Test Accuracy: 0.7015066146850586\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Confusion Matrix:\n",
      "[[507 162]\n",
      " [155 238]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Green       0.77      0.76      0.76       669\n",
      "         Red       0.59      0.61      0.60       393\n",
      "\n",
      "    accuracy                           0.70      1062\n",
      "   macro avg       0.68      0.68      0.68      1062\n",
      "weighted avg       0.70      0.70      0.70      1062\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['label_encoder_v2.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "train_data = pd.read_csv('Training_dt.csv')\n",
    "train_data = train_data.drop('Mask No', axis=1)\n",
    "test_data = pd.read_csv('Testing_dt.csv')\n",
    "test_data = test_data.drop('Mask No', axis=1)\n",
    "\n",
    "# Define columns\n",
    "numerical_cols = ['LEASE_TENOR_INCLUDING_HP', 'CUSTOMER AGE', 'Exp','YOM' ]\n",
    "categorical_cols = ['PRODUCT_NAME', 'Sub_purpose_code_based_on_risk', 'CRIB_SCORE', 'TOTAL INCOME',\n",
    "                    'Percentage_of_Total_Installments_to_Total_Current_Balance_slabs',\n",
    "                    'Percentage_of_Total_Current_Balance_to_Total_Amount_Granted_Limit_slabs',\n",
    "                    'Percentage_of_Total_Arrears_Amount_to_Total_Amount_Granted_Limit_slabs']\n",
    "target_col = 'Cluster'\n",
    "\n",
    "# Preprocessing pipelines for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = train_data.drop(columns=[target_col])\n",
    "y_train = train_data[target_col]\n",
    "\n",
    "X_test = test_data.drop(columns=[target_col])\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=64)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train_encoded)\n",
    "\n",
    "# ANN model with additional hidden layers and tuned hyperparameters\n",
    "model = Sequential()\n",
    "model.add(Dense(39, input_dim=X_train_resampled.shape[1], activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(26, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(13, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(Dense(3, activation='softmax'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(25, activation='relu'))\n",
    "#model.add(Dense(len(np.unique(y_train_resampled)), activation='softmax'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# Compile the model with a lower learning rate and additional epochs\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to avoid overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=30, restore_best_weights=True)\n",
    "\n",
    "# Train the model with more epochs\n",
    "model.fit(X_train_resampled, y_train_resampled, validation_split=0.2, epochs=400, batch_size=64, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_processed, y_test_encoded)\n",
    "print(f'Test Accuracy: {accuracy}')\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_processed)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "y_pred_labels_decoded = label_encoder.inverse_transform(y_pred_labels)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_labels)\n",
    "print('Confusion Matrix:')\n",
    "print(cm)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test_encoded, y_pred_labels, target_names=label_encoder.classes_)\n",
    "print('Classification Report:')\n",
    "print(report)\n",
    "\n",
    "# Save predictions to a new file\n",
    "test_data['Predicted_Cluster'] = y_pred_labels_decoded\n",
    "test_data.to_csv('Testing_dt_with_Predictions.csv', index=False)\n",
    "\n",
    "\n",
    "# Save the model and other necessary files\n",
    "model.save('best_ann_model_v2.h5')\n",
    "#joblib.dump(ml, 'best_ml_model_v2.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessor_v2.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder_v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the test dataset\n",
    "test_data_1242 = pd.read_csv('testing_red.csv')\n",
    "#test_data_1242 = test_data_1242.drop('Mask No', axis=1)\n",
    "\n",
    "# Define columns\n",
    "numerical_cols = ['LEASE_TENOR_INCLUDING_HP', 'CUSTOMER AGE', 'Exp', 'YOM']\n",
    "categorical_cols = ['PRODUCT_NAME', 'Sub_purpose_code_based_on_risk', 'CRIB_SCORE', 'TOTAL INCOME',\n",
    "                    'Percentage_of_Total_Installments_to_Total_Current_Balance_slabs',\n",
    "                    'Percentage_of_Total_Current_Balance_to_Total_Amount_Granted_Limit_slabs',\n",
    "                    'Percentage_of_Total_Arrears_Amount_to_Total_Amount_Granted_Limit_slabs']\n",
    "#target_col = 'Cluster'\n",
    "\n",
    "# Load the pre-trained models and encoders\n",
    "model = tf.keras.models.load_model('best_ann_model_v2.h5')\n",
    "preprocessor = joblib.load('preprocessor_v2.pkl')\n",
    "label_encoder = joblib.load('label_encoder_v2.pkl')\n",
    "\n",
    "# Preprocess the data\n",
    "X_test_1242 = test_data_1242#.drop(columns=[target_col])\n",
    "#y_test_1242 = test_data_1242[target_col]\n",
    "\n",
    "X_test_1242_processed = preprocessor.transform(X_test_1242)\n",
    "#y_test_1242_encoded = label_encoder.transform(y_test_1242)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_1242 = model.predict(X_test_1242_processed)\n",
    "y_pred_1242_labels = np.argmax(y_pred_1242, axis=1)\n",
    "\n",
    "# Decode predictions back to original labels\n",
    "y_pred_1242_labels_decoded = label_encoder.inverse_transform(y_pred_1242_labels)\n",
    "\n",
    "# Generate confusion matrix\n",
    "# cm_1242 = confusion_matrix(y_test_1242_encoded, y_pred_1242_labels)\n",
    "# print('Confusion Matrix:')\n",
    "# print(cm_1242)\n",
    "\n",
    "# # Plot confusion matrix\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(cm_1242, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('Actual')\n",
    "# plt.title('Confusion Matrix for test1242.csv')\n",
    "# plt.show()\n",
    "\n",
    "# Generate classification report\n",
    "# report_1242 = classification_report(y_test_1242_encoded, y_pred_1242_labels, target_names=label_encoder.classes_)\n",
    "# print('Classification Report:')\n",
    "# print(report_1242)\n",
    "\n",
    "# Save predictions to a new file\n",
    "test_data_1242['Predicted_Cluster'] = y_pred_1242_labels_decoded\n",
    "test_data_1242.to_excel('test_red_with_Predictions.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
