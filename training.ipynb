{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest: ROC AUC = 0.9848\n",
      "GradientBoosting: ROC AUC = 0.9479\n",
      "LogisticRegression: ROC AUC = 0.8828\n",
      "Best Algorithm: RandomForestClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-08-26 16:20:24,651] A new study created in memory with name: no-name-654d4cae-a9ad-4046-b1a8-b18412b95b46\n",
      "[I 2024-08-26 16:20:36,234] Trial 0 finished with value: 3.352075594875714e-08 and parameters: {'n_layers': 1, 'n_units_l0': 160, 'dropout_l0': 0.404155752934665, 'optimizer': 'rmsprop', 'learning_rate': 0.0004081178139328964, 'batch_size': 48}. Best is trial 0 with value: 3.352075594875714e-08.\n",
      "[I 2024-08-26 16:20:59,472] Trial 1 finished with value: 5.778598222150322e-08 and parameters: {'n_layers': 4, 'n_units_l0': 448, 'dropout_l0': 0.3607145334191786, 'n_units_l1': 448, 'dropout_l1': 0.45335102015555645, 'n_units_l2': 416, 'dropout_l2': 0.26126579835307473, 'n_units_l3': 352, 'dropout_l3': 0.4270749502374224, 'optimizer': 'rmsprop', 'learning_rate': 0.002135148403626089, 'batch_size': 16}. Best is trial 0 with value: 3.352075594875714e-08.\n",
      "[I 2024-08-26 16:21:04,620] Trial 2 finished with value: 4.9190287398914734e-08 and parameters: {'n_layers': 2, 'n_units_l0': 352, 'dropout_l0': 0.4988293720557662, 'n_units_l1': 288, 'dropout_l1': 0.23683430195952404, 'optimizer': 'rmsprop', 'learning_rate': 0.00106939919984525, 'batch_size': 128}. Best is trial 0 with value: 3.352075594875714e-08.\n",
      "[I 2024-08-26 16:21:13,105] Trial 3 finished with value: 0.0 and parameters: {'n_layers': 3, 'n_units_l0': 224, 'dropout_l0': 0.23912991687736274, 'n_units_l1': 256, 'dropout_l1': 0.43319861831451983, 'n_units_l2': 352, 'dropout_l2': 0.46438260372446466, 'optimizer': 'rmsprop', 'learning_rate': 0.0017780062739676577, 'batch_size': 48}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:22:05,698] Trial 4 finished with value: 6.800759001635015e-05 and parameters: {'n_layers': 4, 'n_units_l0': 128, 'dropout_l0': 0.4093619122157849, 'n_units_l1': 384, 'dropout_l1': 0.2690511083076968, 'n_units_l2': 480, 'dropout_l2': 0.40737842175781264, 'n_units_l3': 352, 'dropout_l3': 0.42863979613343683, 'optimizer': 'rmsprop', 'learning_rate': 1.958110605368465e-05, 'batch_size': 112}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:22:07,025] Trial 5 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:09,318] Trial 6 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:11,806] Trial 7 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:15,540] Trial 8 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.30795171360945583, 'optimizer': 'rmsprop', 'learning_rate': 0.005141777208201318, 'batch_size': 32}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:22:18,087] Trial 9 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:21,842] Trial 10 pruned. Trial was pruned at epoch 8.\n",
      "[I 2024-08-26 16:22:25,208] Trial 11 pruned. Trial was pruned at epoch 6.\n",
      "[I 2024-08-26 16:22:26,560] Trial 12 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-08-26 16:22:31,011] Trial 13 finished with value: 4.6281853904872605e-09 and parameters: {'n_layers': 1, 'n_units_l0': 32, 'dropout_l0': 0.3020724843334128, 'optimizer': 'rmsprop', 'learning_rate': 0.002993542360112435, 'batch_size': 32}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:22:32,725] Trial 14 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:34,745] Trial 15 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:35,704] Trial 16 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:36,993] Trial 17 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:40,179] Trial 18 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:22:42,936] Trial 19 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:43,920] Trial 20 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:45,202] Trial 21 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:22:52,388] Trial 22 finished with value: 6.611718117444099e-11 and parameters: {'n_layers': 1, 'n_units_l0': 64, 'dropout_l0': 0.31896947834156747, 'optimizer': 'rmsprop', 'learning_rate': 0.0029050903460512397, 'batch_size': 32}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:22:53,797] Trial 23 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:54,846] Trial 24 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:56,226] Trial 25 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:22:59,241] Trial 26 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:00,301] Trial 27 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:03,465] Trial 28 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 64, 'dropout_l0': 0.3439902202760358, 'n_units_l1': 256, 'dropout_l1': 0.3236191968926194, 'optimizer': 'rmsprop', 'learning_rate': 0.009517576804036764, 'batch_size': 64}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:23:05,242] Trial 29 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:06,991] Trial 30 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:07,969] Trial 31 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:08,933] Trial 32 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:10,329] Trial 33 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:15,185] Trial 34 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.2825007247635771, 'optimizer': 'rmsprop', 'learning_rate': 0.004085512502627919, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:23:21,506] Trial 35 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 128, 'dropout_l0': 0.2879034334182569, 'n_units_l1': 320, 'dropout_l1': 0.34764586077094584, 'optimizer': 'rmsprop', 'learning_rate': 0.008728454564624313, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:23:27,841] Trial 36 finished with value: 1.3157246847583792e-08 and parameters: {'n_layers': 4, 'n_units_l0': 288, 'dropout_l0': 0.23523907907755168, 'n_units_l1': 224, 'dropout_l1': 0.47728133184242694, 'n_units_l2': 320, 'dropout_l2': 0.3637874206834403, 'n_units_l3': 512, 'dropout_l3': 0.32505632529256673, 'optimizer': 'rmsprop', 'learning_rate': 0.004454451363239846, 'batch_size': 48}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:23:29,555] Trial 37 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:23:31,386] Trial 38 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:33,264] Trial 39 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:36,028] Trial 40 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:23:43,206] Trial 41 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 160, 'dropout_l0': 0.28917169354010036, 'n_units_l1': 320, 'dropout_l1': 0.304103800903359, 'optimizer': 'rmsprop', 'learning_rate': 0.008558803048972366, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:23:45,657] Trial 42 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:23:51,750] Trial 43 finished with value: 2.6446869694218833e-10 and parameters: {'n_layers': 2, 'n_units_l0': 96, 'dropout_l0': 0.273768302154586, 'n_units_l1': 448, 'dropout_l1': 0.34865080671161913, 'optimizer': 'rmsprop', 'learning_rate': 0.003874607068414661, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:23:53,617] Trial 44 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:23:55,408] Trial 45 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:23:57,573] Trial 46 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:02,117] Trial 47 finished with value: 1.3223436234888197e-10 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.29456572566364464, 'optimizer': 'rmsprop', 'learning_rate': 0.007464783342873729, 'batch_size': 32}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:24:03,972] Trial 48 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:05,418] Trial 49 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:08,526] Trial 50 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:10,267] Trial 51 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:15,305] Trial 52 finished with value: 1.388460568740868e-09 and parameters: {'n_layers': 2, 'n_units_l0': 160, 'dropout_l0': 0.3075136861109466, 'n_units_l1': 288, 'dropout_l1': 0.267499028805411, 'optimizer': 'rmsprop', 'learning_rate': 0.007800894338961945, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:24:16,807] Trial 53 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:19,186] Trial 54 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:24:21,145] Trial 55 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:26,645] Trial 56 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 256, 'dropout_l0': 0.20997301452550385, 'optimizer': 'rmsprop', 'learning_rate': 0.007902876611224862, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:24:28,167] Trial 57 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:34,206] Trial 58 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 96, 'dropout_l0': 0.28833910365836657, 'optimizer': 'rmsprop', 'learning_rate': 0.003264208858766841, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:24:35,948] Trial 59 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:37,870] Trial 60 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:42,986] Trial 61 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 256, 'dropout_l0': 0.20103335608403342, 'optimizer': 'rmsprop', 'learning_rate': 0.00794154564641776, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:24:48,094] Trial 62 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 288, 'dropout_l0': 0.21646947983752807, 'optimizer': 'rmsprop', 'learning_rate': 0.009564479199127174, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:24:52,765] Trial 63 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 320, 'dropout_l0': 0.20796512290418148, 'optimizer': 'rmsprop', 'learning_rate': 0.007812571941578226, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:24:53,873] Trial 64 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:24:59,442] Trial 65 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 64, 'dropout_l0': 0.25523495066531343, 'n_units_l1': 384, 'dropout_l1': 0.21217109556865504, 'optimizer': 'rmsprop', 'learning_rate': 0.0061413168031726395, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:25:00,381] Trial 66 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:06,625] Trial 67 finished with value: 6.611718117444099e-11 and parameters: {'n_layers': 1, 'n_units_l0': 128, 'dropout_l0': 0.24757134624193344, 'optimizer': 'rmsprop', 'learning_rate': 0.0038167356555989496, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:25:08,072] Trial 68 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:09,568] Trial 69 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:13,948] Trial 70 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 160, 'dropout_l0': 0.4198215690518115, 'optimizer': 'rmsprop', 'learning_rate': 0.007188813285204079, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:25:16,230] Trial 71 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-08-26 16:25:20,383] Trial 72 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 512, 'dropout_l0': 0.2986094717243155, 'optimizer': 'rmsprop', 'learning_rate': 0.004804056618994988, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:25:21,721] Trial 73 pruned. Trial was pruned at epoch 1.\n",
      "[I 2024-08-26 16:25:23,015] Trial 74 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:24,266] Trial 75 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:26,187] Trial 76 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:27,426] Trial 77 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:28,399] Trial 78 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:31,364] Trial 79 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-08-26 16:25:33,631] Trial 80 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:38,592] Trial 81 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 256, 'dropout_l0': 0.20439465445447041, 'optimizer': 'rmsprop', 'learning_rate': 0.008586449915913097, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:25:43,081] Trial 82 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 288, 'dropout_l0': 0.22636412735086153, 'optimizer': 'rmsprop', 'learning_rate': 0.0071524534377227994, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:25:44,125] Trial 83 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:49,386] Trial 84 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 224, 'dropout_l0': 0.2436104571927608, 'optimizer': 'rmsprop', 'learning_rate': 0.006450280311340381, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:25:50,661] Trial 85 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:52,244] Trial 86 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:56,368] Trial 87 pruned. Trial was pruned at epoch 2.\n",
      "[I 2024-08-26 16:25:57,287] Trial 88 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:25:59,325] Trial 89 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:00,314] Trial 90 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:05,092] Trial 91 finished with value: 0.0 and parameters: {'n_layers': 1, 'n_units_l0': 288, 'dropout_l0': 0.21212631494018983, 'optimizer': 'rmsprop', 'learning_rate': 0.006822250323117473, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:26:06,312] Trial 92 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:07,605] Trial 93 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:08,945] Trial 94 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:10,003] Trial 95 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:15,525] Trial 96 finished with value: 0.0 and parameters: {'n_layers': 2, 'n_units_l0': 64, 'dropout_l0': 0.21056989168559476, 'n_units_l1': 448, 'dropout_l1': 0.41057623229448237, 'optimizer': 'rmsprop', 'learning_rate': 0.004650939990768189, 'batch_size': 16}. Best is trial 3 with value: 0.0.\n",
      "[I 2024-08-26 16:26:16,392] Trial 97 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:17,444] Trial 98 pruned. Trial was pruned at epoch 0.\n",
      "[I 2024-08-26 16:26:19,680] Trial 99 pruned. Trial was pruned at epoch 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9569 - loss: 0.1130\n",
      "Epoch 2/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0046\n",
      "Epoch 3/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0022\n",
      "Epoch 4/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0051\n",
      "Epoch 5/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0019\n",
      "Epoch 6/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0040\n",
      "Epoch 7/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0010    \n",
      "Epoch 8/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0017\n",
      "Epoch 9/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0016\n",
      "Epoch 10/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0017\n",
      "Epoch 11/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.7036e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 9.3806e-04\n",
      "Epoch 13/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0012  \n",
      "Epoch 14/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0021\n",
      "Epoch 15/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0022\n",
      "Epoch 16/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0044\n",
      "Epoch 17/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0040\n",
      "Epoch 18/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0021\n",
      "Epoch 19/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4090e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0033\n",
      "Epoch 21/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6020e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4314e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0037\n",
      "Epoch 24/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4993e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0019\n",
      "Epoch 26/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0032\n",
      "Epoch 27/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0015\n",
      "Epoch 28/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.1513e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.0597e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6605e-06\n",
      "Epoch 31/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 8.7930e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6417e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1035e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0051\n",
      "Epoch 35/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 7.7003e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4424e-05\n",
      "Epoch 37/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 6.1716e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.0657e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 40/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 41/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9991 - loss: 0.0043\n",
      "Epoch 42/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.3426e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3783e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.1027e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 8.4051e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.3791e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.1446e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4561e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.8982e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.2465e-05\n",
      "Epoch 51/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5734e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9987 - loss: 0.0056\n",
      "Epoch 53/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 4.9547e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0013\n",
      "Epoch 55/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 9.1258e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.6216e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 2.7998e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9996 - loss: 0.0025\n",
      "Epoch 59/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 7.0914e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 8.9676e-05\n",
      "Epoch 61/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.1605e-05\n",
      "Epoch 62/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.9146e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 4.5450e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 3.0935e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 1.1067e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.4657e-05\n",
      "Epoch 67/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 0.0011\n",
      "Epoch 68/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.9472e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 3.9635e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.1118e-06\n",
      "Epoch 71/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.5586e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6179e-06\n",
      "Epoch 73/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9997 - loss: 3.9400e-04\n",
      "Epoch 74/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1864e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.9294e-08\n",
      "Epoch 76/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1192e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0388e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1142e-06\n",
      "Epoch 79/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1187e-05\n",
      "Epoch 80/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9450e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 1.6235e-04\n",
      "Epoch 82/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1913e-06\n",
      "Epoch 83/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8976e-05\n",
      "Epoch 84/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0023\n",
      "Epoch 85/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0040\n",
      "Epoch 86/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.1692e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4699e-06\n",
      "Epoch 88/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0017\n",
      "Epoch 89/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4924e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.1396e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 2.3919e-04\n",
      "Epoch 92/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.5843e-04\n",
      "Epoch 93/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0026\n",
      "Epoch 94/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0011\n",
      "Epoch 95/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3017e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2379e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2899e-04\n",
      "Epoch 98/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8617e-07\n",
      "Epoch 99/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0014\n",
      "Epoch 100/100\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 9.9212e-04\n",
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6440677966101694\n",
      "ROC AUC: 0.7002647223268179\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.58      0.67       669\n",
      "           1       0.51      0.76      0.61       393\n",
      "\n",
      "    accuracy                           0.64      1062\n",
      "   macro avg       0.66      0.67      0.64      1062\n",
      "weighted avg       0.69      0.64      0.65      1062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "train_data = pd.read_csv('Training_dt.csv')\n",
    "train_data = train_data.drop('Mask No', axis=1)\n",
    "test_data = pd.read_csv('Testing_dt.csv')\n",
    "test_data = test_data.drop('Mask No', axis=1)\n",
    "\n",
    "# # Define columns\n",
    "# numerical_cols = ['LEASE_TENOR_INCLUDING_HP', 'YOM', 'CUSTOMER AGE', 'Exp']\n",
    "# categorical_cols = ['PRODUCT_NAME', 'Sub_purpose_code_based_on_risk', 'CRIB_SCORE', 'TOTAL INCOME',\n",
    "#                     'Percentage_of_Total_Current_Balance_to_Total_Amount_Granted_Limit_slabs',\n",
    "#                     'Percentage_of_Total_Arrears_Amount_to_Total_Amount_Granted_Limit_slabs',\n",
    "#                     'Percentage_of_Total_Installments_to_Total_Current_Balance_slabs']\n",
    "# target_col = 'Cluster'\n",
    "\n",
    "\n",
    "# Define columns\n",
    "numerical_cols = ['LEASE_TENOR_INCLUDING_HP', 'CUSTOMER AGE', 'Exp', 'YOM']\n",
    "categorical_cols = ['PRODUCT_NAME', 'Sub_purpose_code_based_on_risk', 'CRIB_SCORE','TOTAL INCOME',\n",
    "                    'Percentage_of_Total_Installments_to_Total_Current_Balance_slabs',\n",
    "                    'Percentage_of_Total_Current_Balance_to_Total_Amount_Granted_Limit_slabs',\n",
    "                    'Percentage_of_Total_Arrears_Amount_to_Total_Amount_Granted_Limit_slabs']\n",
    "target_col = 'Cluster'\n",
    "\n",
    "\n",
    "\n",
    "# Define X and y\n",
    "X_train = train_data[numerical_cols + categorical_cols]\n",
    "y_train = train_data[target_col]\n",
    "X_test = test_data[numerical_cols + categorical_cols]\n",
    "y_test = test_data[target_col]\n",
    "\n",
    "# Encode categorical columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)])\n",
    "\n",
    "# Preprocess the data\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Apply SMOTEENN to handle class imbalance\n",
    "smoteenn = SMOTEENN(sampling_strategy='auto')\n",
    "X_resampled, y_resampled = smoteenn.fit_resample(X_train_processed, y_train)\n",
    "\n",
    "# Encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_resampled = label_encoder.fit_transform(y_resampled)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Define ML algorithms\n",
    "ml_algorithms = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoosting': GradientBoostingClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Cross-validation to select the best ML algorithm\n",
    "best_algorithm = None\n",
    "best_score = -np.inf\n",
    "\n",
    "for name, clf in ml_algorithms.items():\n",
    "    try:\n",
    "        scores = cross_val_score(clf, X_resampled, y_resampled, \n",
    "                                 cv=StratifiedKFold(n_splits=5), \n",
    "                                 scoring='roc_auc_ovr')\n",
    "        mean_score = np.mean(scores)\n",
    "        print(f\"{name}: ROC AUC = {mean_score:.4f}\")\n",
    "        if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_algorithm = clf\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {name}: {e}\")\n",
    "\n",
    "# Check if a valid algorithm was selected\n",
    "if best_algorithm is None:\n",
    "    raise ValueError(\"No valid machine learning algorithm was selected.\")\n",
    "\n",
    "print(f\"Best Algorithm: {best_algorithm.__class__.__name__}\")\n",
    "\n",
    "# Fit the best ML algorithm on the entire training set\n",
    "best_algorithm.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Use the predictions of the best ML algorithm as additional input to the ANN\n",
    "ml_train_predictions = best_algorithm.predict_proba(X_resampled)\n",
    "ml_test_predictions = best_algorithm.predict_proba(X_test_processed)\n",
    "\n",
    "# Concatenate the ML algorithm's predictions with the original input features\n",
    "X_train_combined = np.hstack([X_resampled, ml_train_predictions])\n",
    "X_test_combined = np.hstack([X_test_processed, ml_test_predictions])\n",
    "\n",
    "# Define the model using the functional API and Optuna for hyperparameter tuning\n",
    "def create_model(trial):\n",
    "    # Suggest the number of layers and neurons\n",
    "    n_layers = trial.suggest_int('n_layers', 1, 4)\n",
    "    inputs = Input(shape=(X_train_combined.shape[1],))\n",
    "    x = inputs\n",
    "\n",
    "    for i in range(n_layers):\n",
    "        num_neurons = trial.suggest_int(f'n_units_l{i}', 32, 512, step=32)\n",
    "        x = Dense(num_neurons, activation='relu')(x)\n",
    "        x = BatchNormalization()(x)  # Added batch normalization\n",
    "        dropout_rate = trial.suggest_float(f'dropout_l{i}', 0.2, 0.5)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    # Output layer\n",
    "    outputs = Dense(len(np.unique(y_resampled)), activation='softmax')(x)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "    # Suggest optimizer and learning rate\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-3, 1e-2, log=True)\n",
    "    \n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    \n",
    "    history = model.fit(X_train_combined, y_resampled, \n",
    "                        validation_split=0.2, \n",
    "                        epochs=100, \n",
    "                        batch_size=trial.suggest_int('batch_size', 16, 128, step=16),\n",
    "                        callbacks=[TFKerasPruningCallback(trial, 'val_loss'), early_stopping],\n",
    "                        verbose=0)\n",
    "    \n",
    "    # Evaluate on the validation set\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    return val_loss\n",
    "\n",
    "# Run the hyperparameter optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)  # Increased number of trials\n",
    "\n",
    "# Train the best model on the entire training data\n",
    "best_trial = study.best_trial\n",
    "model = create_model(best_trial)\n",
    "\n",
    "# Final training with the best hyperparameters\n",
    "model.fit(X_train_combined, y_resampled, \n",
    "          epochs=100,  # Fixed number of epochs\n",
    "          batch_size=best_trial.params['batch_size'],\n",
    "          verbose=1)\n",
    "\n",
    "# Evaluate on the test data\n",
    "y_pred_prob = model.predict(X_test_combined)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test_encoded, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(tf.keras.utils.to_categorical(y_test_encoded), y_pred_prob, multi_class='ovr'))\n",
    "print(classification_report(y_test_encoded, y_pred))\n",
    "\n",
    "# Save the model\n",
    "model.save('best_model.h5')\n",
    "\n",
    "# Save the best hyperparameters\n",
    "with open('best_hyperparameters.txt', 'w') as f:\n",
    "    f.write(str(best_trial.params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder saved as 'label_encoder.pkl'\n",
      "Preprocessor saved as 'preprocessor.pkl'\n",
      "Best ML model saved as 'best_ml_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the LabelEncoder\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "print(\"LabelEncoder saved as 'label_encoder.pkl'\")\n",
    "\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.pkl')\n",
    "print(\"Preprocessor saved as 'preprocessor.pkl'\")\n",
    "\n",
    "# Save the best ML model\n",
    "joblib.dump(best_algorithm, 'best_ml_model.pkl')\n",
    "print(\"Best ML model saved as 'best_ml_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m34/34\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "Predictions saved to 'test_set_predictions.csv'\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the test set\n",
    "y_pred_prob = model.predict(X_test_combined)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Inverse transform the encoded target variable to get the original labels\n",
    "y_pred_actual = label_encoder.inverse_transform(y_pred)\n",
    "y_test_actual = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "# Retrieve the original categorical values from the test set\n",
    "X_test_original = X_test.copy()\n",
    "\n",
    "# Create a DataFrame with the predictions and actual values\n",
    "predictions_df = X_test_original.copy()\n",
    "predictions_df[target_col] = y_test_actual  # Actual target values from the test set\n",
    "predictions_df['Predicted_' + target_col] = y_pred_actual  # Predicted target values\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "predictions_df.to_csv('test_set_predictions.csv', index=False)\n",
    "\n",
    "print(\"Predictions saved to 'test_set_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'new_data_with_predictions.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m new_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m target_col] \u001b[38;5;241m=\u001b[39m y_pred_actual\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Save the new dataset with predictions to a CSV file\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43mnew_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnew_data_with_predictions.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBulk predictions saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew_data_with_predictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\generic.py:3902\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3891\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3893\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3894\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3895\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3899\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3900\u001b[0m )\n\u001b[1;32m-> 3902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3903\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3904\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3905\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3906\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3907\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3908\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3909\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3910\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\formats\\format.py:1152\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m   1134\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m   1135\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1151\u001b[0m )\n\u001b[1;32m-> 1152\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\formats\\csvs.py:247\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    257\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    258\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    264\u001b[0m     )\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'new_data_with_predictions.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model, preprocessor, and label encoder\n",
    "model = tf.keras.models.load_model('best_model.h5')\n",
    "preprocessor = joblib.load('preprocessor.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "# Load the new dataset (assuming it has the same structure as the test set)\n",
    "new_data = pd.read_csv('Testing535.csv')\n",
    "\n",
    "# Drop any unnecessary columns (e.g., 'Mask No' if present)\n",
    "#new_data = new_data.drop('Mask No', axis=1)\n",
    "\n",
    "# Define the columns used in the model\n",
    "numerical_cols = ['LEASE_TENOR_INCLUDING_HP', 'CUSTOMER AGE', 'Exp', 'YOM']\n",
    "categorical_cols = ['PRODUCT_NAME', 'Sub_purpose_code_based_on_risk', 'CRIB_SCORE', 'TOTAL INCOME',\n",
    "                    'Percentage_of_Total_Installments_to_Total_Current_Balance_slabs',\n",
    "                    'Percentage_of_Total_Current_Balance_to_Total_Amount_Granted_Limit_slabs',\n",
    "                    'Percentage_of_Total_Arrears_Amount_to_Total_Amount_Granted_Limit_slabs']\n",
    "target_col = 'Cluster'\n",
    "\n",
    "# Preprocess the new data\n",
    "X_new_processed = preprocessor.transform(new_data[numerical_cols + categorical_cols])\n",
    "\n",
    "# Load the best ML model\n",
    "best_algorithm = joblib.load('best_ml_model.pkl')\n",
    "\n",
    "# Generate predictions using the best ML model\n",
    "ml_new_predictions = best_algorithm.predict_proba(X_new_processed)\n",
    "\n",
    "# Concatenate the ML algorithm's predictions with the original input features\n",
    "X_new_combined = np.hstack([X_new_processed, ml_new_predictions])\n",
    "\n",
    "# Make predictions using the trained ANN model\n",
    "y_pred_prob = model.predict(X_new_combined)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Inverse transform the encoded target variable to get the original labels\n",
    "y_pred_actual = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Add predictions to the new data\n",
    "new_data['Predicted_' + target_col] = y_pred_actual\n",
    "\n",
    "# Save the new dataset with predictions to a CSV file\n",
    "new_data.to_csv('new_data_with_predictions.csv', index=False)\n",
    "\n",
    "print(\"Bulk predictions saved to 'new_data_with_predictions.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [1062, 534]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, ConfusionMatrixDisplay\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming you have y_test_encoded (actual labels) and y_pred (predicted labels)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Generate the confusion matrix\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix using seaborn\u001b[39;00m\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:342\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    248\u001b[0m     {\n\u001b[0;32m    249\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    258\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    259\u001b[0m ):\n\u001b[0;32m    260\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    344\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\metrics\\_classification.py:103\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[1;32m--> 103\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [1062, 534]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Assuming you have y_test_encoded (actual labels) and y_pred (predicted labels)\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test_encoded, y_pred)\n",
    "\n",
    "# Plot the confusion matrix using seaborn\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Optionally, you can use ConfusionMatrixDisplay for a more customized plot\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
